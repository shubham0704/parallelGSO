{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_path):\n",
    "    dataset = pd.read_csv(data_path)\n",
    "    X = dataset.iloc[:, 3:13].values\n",
    "    y = dataset.iloc[:, 13].values\n",
    "    labelencoder_X_1 = LabelEncoder()\n",
    "    X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "    labelencoder_X_2 = LabelEncoder()\n",
    "    X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    X = onehotencoder.fit_transform(X).toarray()\n",
    "    X = X[:, 1:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = preprocess('datasets/Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_per_layer=[11,6,1]\n",
    "kernel_init='uniform'\n",
    "activation=['relu','relu', 'sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_net import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NeuralNetwork(units_per_layer, kernel_init, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 400\n",
    "epochs = 10\n",
    "mini_batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgso.gso import GSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of weights - 72\n",
      "starting with gso_batch size - 400, mini_batch_size -1400 \n",
      "completed epoch 0 --------> loss_value: 1.9626476688274832\n",
      "completed epoch 1 --------> loss_value: 1.7926326477460264\n",
      "completed epoch 2 --------> loss_value: 1.5557752671425333\n",
      "completed epoch 3 --------> loss_value: 1.731911753106524\n",
      "completed epoch 4 --------> loss_value: 1.5518106384416386\n",
      "completed epoch 5 --------> loss_value: 1.54843739311076\n",
      "completed epoch 6 --------> loss_value: 1.4924188369333666\n",
      "completed epoch 7 --------> loss_value: 1.515088324173585\n",
      "completed epoch 8 --------> loss_value: 1.256670657765428\n",
      "completed epoch 9 --------> loss_value: 1.2577846995865671\n",
      "completed epoch 10 --------> loss_value: 1.2434997710018643\n",
      "completed epoch 11 --------> loss_value: 1.2614799555179432\n",
      "completed epoch 12 --------> loss_value: 1.2471511537818403\n",
      "completed epoch 13 --------> loss_value: 1.2514284708006922\n",
      "completed epoch 14 --------> loss_value: 1.2471658722378811\n",
      "completed epoch 15 --------> loss_value: 1.2342655320590188\n",
      "completed epoch 16 --------> loss_value: 1.2441951727701959\n",
      "completed epoch 17 --------> loss_value: 1.2387778515237644\n",
      "completed epoch 18 --------> loss_value: 1.2322334724111332\n",
      "completed epoch 19 --------> loss_value: 1.2434485432549054\n"
     ]
    }
   ],
   "source": [
    "bounds = [-10, 10]\n",
    "num_particles = 200\n",
    "max_iter = 25\n",
    "train_data = (X_train, y_train)\n",
    "epochs = 20\n",
    "mini_batch_size = 1400\n",
    "batch_size = 400\n",
    "classifier = GSO(bounds, num_particles, max_iter, classifier, train_data, epochs,batch_size, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for example  in X_test:\n",
    "    y_pred = classifier.forward_pass(example)\n",
    "    predicted.append(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.array(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = (predicted > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.807"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
