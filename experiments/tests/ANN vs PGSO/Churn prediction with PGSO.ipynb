{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_path):\n",
    "    dataset = pd.read_csv(data_path)\n",
    "    X = dataset.iloc[:, 3:13].values\n",
    "    y = dataset.iloc[:, 13].values\n",
    "    labelencoder_X_1 = LabelEncoder()\n",
    "    X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "    labelencoder_X_2 = LabelEncoder()\n",
    "    X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "    X = onehotencoder.fit_transform(X).toarray()\n",
    "    X = X[:, 1:]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = preprocess('datasets/Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_per_layer=[11,6,1]\n",
    "kernel_init='uniform'\n",
    "activation=['relu','relu', 'sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting neural_net.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile neural_net.py\n",
    "from collections import OrderedDict\n",
    "from scipy.special import expit\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    NeuralNetwork:{\n",
    "    layer_id:{\n",
    "                weights: np.array()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    Example:\n",
    "    NeuralNetwork:{\n",
    "    1:{\n",
    "        'weights':[0.1,-0.54,0.32]\n",
    "        }\n",
    "    2:{\n",
    "        'weights':[0.31,-0.344,0.41, 0.89]\n",
    "        }    \n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, units_per_layer, kernel_init, activation):\n",
    "        self.units_per_layer = units_per_layer\n",
    "        self.kernel_init = kernel_init\n",
    "        self.activation = activation\n",
    "        self.layers = OrderedDict()\n",
    "        \n",
    "        # initialize weights and biases \n",
    "        for layer_id, units in enumerate(self.units_per_layer[:-1]):\n",
    "            prev_dims = self.units_per_layer[layer_id]\n",
    "            num_units = self.units_per_layer[layer_id+1]\n",
    "            layer_dims = (num_units, prev_dims)\n",
    "            #layer_dims = (prev_dims, num_units, self.batch_size)\n",
    "            \n",
    "            self.layers[layer_id+1] = {}\n",
    "            self.layers[layer_id+1]['weights'] = np.random.uniform(-1,1, layer_dims)\n",
    "            # we can add biases later if we want\n",
    "    \n",
    "    def forward_pass(self, ipt_matrix):\n",
    "        \n",
    "        for layer_id, layer in self.layers.items():\n",
    "            #print('layer number ->', layer_id)\n",
    "            V = np.dot((ipt_matrix), (layer['weights'].T))\n",
    "                \n",
    "#                 print('multiplied matrices -> \\n weights -> {}, \\\n",
    "#                 ipt_matrix ->{}'.format(layer['weights'].T.shape, ipt_matrix.shape))\n",
    "#                 print('output matrix shape ', V.shape)\n",
    "            y = self.activation_function(V,activation_type=self.activation[int(layer_id)])\n",
    "            ipt_matrix = y\n",
    "            \n",
    "        return y\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def activation_function(V, activation_type='relu'):\n",
    "        if activation_type == 'relu':\n",
    "            return np.maximum(V, 0, V)\n",
    "        elif activation_type == 'sigmoid':\n",
    "            return expit(V)\n",
    "        else:\n",
    "            raise('activation type {} not found!'.format(activation_type))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = NeuralNetwork(units_per_layer, kernel_init, activation, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of layer 1  (6, 11)\n",
      "shape of layer 2  (1, 6)\n"
     ]
    }
   ],
   "source": [
    "print('shape of layer 1 ',classifier.layers[1]['weights'].shape)\n",
    "print('shape of layer 2 ',classifier.layers[2]['weights'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 11) id to sample:  [6252 3658 1243 5052] shape of y_train (8000, 1)\n"
     ]
    }
   ],
   "source": [
    "# lets try to randomly sample a batch of batch_size\n",
    "sample_idxs = np.random.choice(X_train.shape[0], batch_size, replace=False)\n",
    "sample_training_batch = X_train[sample_idxs, :]\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "sample_training_answer = y_train[sample_idxs, :]\n",
    "sample_training_batch.shape\n",
    "print(X_train.shape, 'id to sample: ', sample_idxs, 'shape of y_train', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer number -> 1\n",
      "multiplied matrices -> \n",
      " weights -> (11, 6),                 ipt_matrix ->(4, 11)\n",
      "output matrix shape  (4, 6)\n",
      "layer number -> 2\n",
      "multiplied matrices -> \n",
      " weights -> (6, 1),                 ipt_matrix ->(4, 6)\n",
      "output matrix shape  (4, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.13200311],\n",
       "       [0.1918486 ],\n",
       "       [0.78970992],\n",
       "       [0.541071  ]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.forward_pass(sample_training_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
